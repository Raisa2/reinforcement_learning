{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUXOEl1XEp5b"
      },
      "outputs": [],
      "source": [
        "# Importing needed librarys\n",
        "import torch\n",
        "import torch.distributions as dist\n",
        "import torch.nn as nn\n",
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyToLykCFigi"
      },
      "outputs": [],
      "source": [
        "# Setting seeds\n",
        "def make_deterministic(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zz6W_au2FlH3"
      },
      "outputs": [],
      "source": [
        "# Building a class for the neural network\n",
        "class Neural_Network(nn.Module):\n",
        "  def __init__(self, in_dim, out_dim, hidden_dim):\n",
        "        super(Neural_Network, self).__init__()\n",
        "        self.input_layer = nn.Linear(in_dim, hidden_dim[0])\n",
        "        self.hidden_layer_1 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
        "        self.hidden_layer_2 = nn.Linear(hidden_dim[1], hidden_dim[2])\n",
        "        self.output_layer = nn.Linear(hidden_dim[2], out_dim)\n",
        "       \n",
        "  def forward (self, x, activation_function = nn.ReLU()):\n",
        "    x = activation_function(self.input_layer(x))\n",
        "    x = activation_function(self.hidden_layer_1(x))\n",
        "    x = activation_function(self.hidden_layer_2(x))\n",
        "    output = self.output_layer(x)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvqQNtUyFvqC"
      },
      "outputs": [],
      "source": [
        "# Defining function for playing during and after training to obtain performance of the agent\n",
        "def play(episodes, step, end, envs):\n",
        "  x = 0\n",
        "  returns = []\n",
        "\n",
        "  for i in range(0, episodes):\n",
        "    memory_rewards = []\n",
        "    state = envs.reset()\n",
        "    \n",
        "    while True:\n",
        "      state_tensor = torch.tensor(state, dtype=torch.float32) \n",
        "      values = policy_model(state_tensor)\n",
        "      distribution = dist.Categorical(logits = values)\n",
        "      action = distribution.sample()\n",
        "      state_next, reward, done, _ = envs.step(action.item())\n",
        "      memory_rewards.append(reward)\n",
        "      state = state_next\n",
        "\n",
        "      if done:\n",
        "        x = sum(memory_rewards)\n",
        "        state = envs.reset()\n",
        "        returns.append(x)\n",
        "        break\n",
        "\n",
        "  if end:\n",
        "    avg_return = sum(returns[-100:]) / 100\n",
        "    print(\"Average return over 100 episodes of trained agent:\", avg_return)\n",
        "  else:\n",
        "    avg_return = sum(returns[-25:]) / 25\n",
        "    wandb.log({\"Average return over 25 episodes of playing\": avg_return,\"step\": step})\n",
        "    print(\"Average return over 25 episodes of playing:\", avg_return)\n",
        "\n",
        "  return avg_return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "95b7af2cb84d4434baf86a7f680b1ff2",
            "456f8ab95d854d1f873a0d54014e0482",
            "d2b88aad5a1240c2aead34f00bff4b3a",
            "5a275eb8ded84ec0a968bcbea85c6297",
            "397ba1f5c42c465dad612f3796b8db92",
            "4136a7a66bbc461483498cd98e327cdd",
            "c0b862fdb80c4b868225296c904f6b9f",
            "a3e1ceffc5094cc9a2be49d2fda3615a",
            "4059350189204ee793a98052fcdae5ee",
            "923267aef11b492d986bb28eeffd77a7",
            "aa524deafd0d495eabd5f3913538acb2",
            "b59e4a729a064169afeb395b91600c5f",
            "60a57683952f417cb676cc079ff4373c",
            "ca39849f156f4f0ba346c9238baecc94",
            "f760b44c276a42b5aacebfc41cc7e2ab",
            "20440a3cb2af4e5aa4c2a81958ad006b"
          ]
        },
        "id": "_jHgeo0zPbic",
        "outputId": "f1ac00f9-0ab5-4b4a-83b0-ed3c3fddf566"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/raisa/Reinforce-Baseline-CartPole/runs/aqlsdy3d\" target=\"_blank\">celestial-eon-303</a></strong> to <a href=\"https://wandb.ai/raisa/Reinforce-Baseline-CartPole\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SEED: 12\n",
            "1 10.0\n",
            "2 37.0\n",
            "3 16.0\n",
            "4 9.0\n",
            "5 12.0\n",
            "6 20.0\n",
            "7 12.0\n",
            "8 15.0\n",
            "9 13.0\n",
            "10 23.0\n",
            "11 17.0\n",
            "12 10.0\n",
            "13 15.0\n",
            "14 9.0\n",
            "15 29.0\n",
            "16 20.0\n",
            "17 28.0\n",
            "18 21.0\n",
            "19 16.0\n",
            "20 63.0\n",
            "21 10.0\n",
            "22 13.0\n",
            "23 31.0\n",
            "24 19.0\n",
            "Average return over 25 episodes of playing: 19.52\n",
            "25 41.0\n",
            "26 42.0\n",
            "27 33.0\n",
            "28 14.0\n",
            "29 36.0\n",
            "30 31.0\n",
            "31 22.0\n",
            "32 14.0\n",
            "33 21.0\n",
            "34 31.0\n",
            "35 34.0\n",
            "36 27.0\n",
            "37 24.0\n",
            "38 24.0\n",
            "39 16.0\n",
            "40 22.0\n",
            "41 12.0\n",
            "42 59.0\n",
            "43 24.0\n",
            "Average return over 25 episodes of playing: 28.36\n",
            "44 20.0\n",
            "45 12.0\n",
            "46 21.0\n",
            "47 41.0\n",
            "48 42.0\n",
            "49 18.0\n",
            "50 19.0\n",
            "51 21.0\n",
            "52 27.0\n",
            "53 49.0\n",
            "54 10.0\n",
            "55 20.0\n",
            "56 29.0\n",
            "57 39.0\n",
            "58 13.0\n",
            "59 16.0\n",
            "60 29.0\n",
            "61 36.0\n",
            "62 18.0\n",
            "63 11.0\n",
            "Average return over 25 episodes of playing: 25.64\n",
            "64 29.0\n",
            "65 24.0\n",
            "66 16.0\n",
            "67 10.0\n",
            "68 14.0\n",
            "69 19.0\n",
            "70 14.0\n",
            "71 10.0\n",
            "72 11.0\n",
            "73 26.0\n",
            "74 30.0\n",
            "75 17.0\n",
            "76 26.0\n",
            "77 14.0\n",
            "78 10.0\n",
            "79 13.0\n",
            "80 10.0\n",
            "81 16.0\n",
            "82 17.0\n",
            "83 18.0\n",
            "84 21.0\n",
            "85 43.0\n",
            "86 21.0\n",
            "87 19.0\n",
            "88 16.0\n",
            "89 9.0\n",
            "90 30.0\n",
            "Average return over 25 episodes of playing: 24.04\n",
            "91 14.0\n",
            "92 75.0\n",
            "93 15.0\n",
            "94 25.0\n",
            "95 67.0\n",
            "96 49.0\n",
            "97 16.0\n",
            "98 43.0\n",
            "99 13.0\n",
            "100 22.0\n",
            "101 36.0\n",
            "Average return training: 23.54\n",
            "102 25.0\n",
            "Average return training: 23.42\n",
            "103 16.0\n",
            "Average return training: 23.42\n",
            "104 74.0\n",
            "Average return training: 24.07\n",
            "105 16.0\n",
            "Average return training: 24.11\n",
            "Average return over 25 episodes of playing: 32.4\n",
            "106 61.0\n",
            "Average return training: 24.52\n",
            "107 90.0\n",
            "Average return training: 25.3\n",
            "108 12.0\n",
            "Average return training: 25.27\n",
            "109 41.0\n",
            "Average return training: 25.55\n",
            "110 19.0\n",
            "Average return training: 25.51\n",
            "111 14.0\n",
            "Average return training: 25.48\n",
            "112 94.0\n",
            "Average return training: 26.32\n",
            "113 54.0\n",
            "Average return training: 26.71\n",
            "114 18.0\n",
            "Average return training: 26.8\n",
            "115 21.0\n",
            "Average return training: 26.72\n",
            "116 51.0\n",
            "Average return training: 27.03\n",
            "Average return over 25 episodes of playing: 38.88\n",
            "117 65.0\n",
            "Average return training: 27.4\n",
            "118 28.0\n",
            "Average return training: 27.47\n",
            "119 24.0\n",
            "Average return training: 27.55\n",
            "120 40.0\n",
            "Average return training: 27.32\n",
            "121 30.0\n",
            "Average return training: 27.52\n",
            "122 35.0\n",
            "Average return training: 27.74\n",
            "123 136.0\n",
            "Average return training: 28.79\n",
            "124 15.0\n",
            "Average return training: 28.75\n",
            "125 18.0\n",
            "Average return training: 28.52\n",
            "126 62.0\n",
            "Average return training: 28.72\n",
            "127 45.0\n",
            "Average return training: 28.84\n",
            "Average return over 25 episodes of playing: 39.68\n",
            "128 131.0\n",
            "Average return training: 30.01\n",
            "129 79.0\n",
            "Average return training: 30.44\n",
            "130 61.0\n",
            "Average return training: 30.74\n",
            "131 44.0\n",
            "Average return training: 30.96\n",
            "132 114.0\n",
            "Average return training: 31.96\n",
            "133 29.0\n",
            "Average return training: 32.04\n",
            "134 50.0\n",
            "Average return training: 32.23\n",
            "Average return over 25 episodes of playing: 52.32\n",
            "135 40.0\n",
            "Average return training: 32.29\n",
            "136 111.0\n",
            "Average return training: 33.13\n",
            "137 86.0\n",
            "Average return training: 33.75\n",
            "138 38.0\n",
            "Average return training: 33.89\n",
            "139 51.0\n",
            "Average return training: 34.24\n",
            "140 75.0\n",
            "Average return training: 34.77\n",
            "141 30.0\n",
            "Average return training: 34.95\n",
            "142 44.0\n",
            "Average return training: 34.8\n",
            "143 26.0\n",
            "Average return training: 34.82\n",
            "Average return over 25 episodes of playing: 75.8\n",
            "144 75.0\n",
            "Average return training: 35.37\n",
            "145 87.0\n",
            "Average return training: 36.12\n",
            "146 93.0\n",
            "Average return training: 36.84\n",
            "147 49.0\n",
            "Average return training: 36.92\n",
            "148 149.0\n",
            "Average return training: 37.99\n",
            "Average return over 25 episodes of playing: 65.28\n",
            "149 109.0\n",
            "Average return training: 38.9\n",
            "150 79.0\n",
            "Average return training: 39.5\n",
            "151 16.0\n",
            "Average return training: 39.45\n",
            "152 70.0\n",
            "Average return training: 39.88\n",
            "153 69.0\n",
            "Average return training: 40.08\n",
            "154 77.0\n",
            "Average return training: 40.75\n",
            "155 107.0\n",
            "Average return training: 41.62\n",
            "Average return over 25 episodes of playing: 73.2\n",
            "156 55.0\n",
            "Average return training: 41.88\n",
            "157 122.0\n",
            "Average return training: 42.71\n",
            "158 129.0\n",
            "Average return training: 43.87\n",
            "159 106.0\n",
            "Average return training: 44.77\n",
            "Average return over 25 episodes of playing: 78.48\n",
            "160 162.0\n",
            "Average return training: 46.1\n",
            "161 62.0\n",
            "Average return training: 46.36\n",
            "162 80.0\n",
            "Average return training: 46.98\n",
            "163 45.0\n",
            "Average return training: 47.32\n",
            "164 84.0\n",
            "Average return training: 47.87\n",
            "165 92.0\n",
            "Average return training: 48.55\n",
            "166 83.0\n",
            "Average return training: 49.22\n",
            "Average return over 25 episodes of playing: 99.72\n",
            "167 41.0\n",
            "Average return training: 49.53\n",
            "168 64.0\n",
            "Average return training: 50.03\n",
            "169 85.0\n",
            "Average return training: 50.69\n",
            "170 104.0\n",
            "Average return training: 51.59\n",
            "171 47.0\n",
            "Average return training: 51.96\n",
            "172 50.0\n",
            "Average return training: 52.35\n",
            "173 97.0\n",
            "Average return training: 53.06\n",
            "Average return over 25 episodes of playing: 58.0\n",
            "174 70.0\n",
            "Average return training: 53.46\n",
            "175 69.0\n",
            "Average return training: 53.98\n",
            "176 91.0\n",
            "Average return training: 54.63\n",
            "177 159.0\n",
            "Average return training: 56.08\n",
            "178 45.0\n",
            "Average return training: 56.43\n",
            "179 49.0\n",
            "Average return training: 56.79\n",
            "Average return over 25 episodes of playing: 95.16\n",
            "180 85.0\n",
            "Average return training: 57.54\n",
            "181 256.0\n",
            "Average return training: 59.94\n",
            "182 97.0\n",
            "Average return training: 60.74\n",
            "183 93.0\n",
            "Average return training: 61.49\n",
            "Average return over 25 episodes of playing: 105.2\n",
            "184 58.0\n",
            "Average return training: 61.86\n",
            "185 99.0\n",
            "Average return training: 62.42\n",
            "186 122.0\n",
            "Average return training: 63.43\n",
            "187 95.0\n",
            "Average return training: 64.19\n",
            "188 93.0\n",
            "Average return training: 64.96\n",
            "Average return over 25 episodes of playing: 106.64\n",
            "189 112.0\n",
            "Average return training: 65.99\n",
            "190 120.0\n",
            "Average return training: 66.89\n",
            "191 101.0\n",
            "Average return training: 67.76\n",
            "192 163.0\n",
            "Average return training: 68.64\n",
            "Average return over 25 episodes of playing: 157.28\n",
            "193 61.0\n",
            "Average return training: 69.1\n",
            "194 103.0\n",
            "Average return training: 69.88\n",
            "195 235.0\n",
            "Average return training: 71.56\n",
            "196 69.0\n",
            "Average return training: 71.76\n",
            "Average return over 25 episodes of playing: 140.4\n",
            "197 112.0\n",
            "Average return training: 72.72\n",
            "198 187.0\n",
            "Average return training: 74.16\n",
            "199 136.0\n",
            "Average return training: 75.39\n",
            "200 124.0\n",
            "Average return training: 76.41\n",
            "Average return over 25 episodes of playing: 220.72\n",
            "201 135.0\n",
            "Average return training: 77.4\n",
            "202 115.0\n",
            "Average return training: 78.3\n",
            "203 170.0\n",
            "Average return training: 79.84\n",
            "Average return over 25 episodes of playing: 166.0\n",
            "204 228.0\n",
            "Average return training: 81.38\n",
            "205 129.0\n",
            "Average return training: 82.51\n",
            "206 101.0\n",
            "Average return training: 82.91\n",
            "207 131.0\n",
            "Average return training: 83.32\n",
            "Average return over 25 episodes of playing: 179.08\n",
            "208 95.0\n",
            "Average return training: 84.15\n",
            "209 109.0\n",
            "Average return training: 84.83\n",
            "210 172.0\n",
            "Average return training: 86.36\n",
            "211 110.0\n",
            "Average return training: 87.32\n",
            "Average return over 25 episodes of playing: 189.32\n",
            "212 111.0\n",
            "Average return training: 87.49\n",
            "213 143.0\n",
            "Average return training: 88.38\n",
            "214 139.0\n",
            "Average return training: 89.59\n",
            "215 139.0\n",
            "Average return training: 90.77\n",
            "Average return over 25 episodes of playing: 119.28\n",
            "216 118.0\n",
            "Average return training: 91.44\n",
            "217 111.0\n",
            "Average return training: 91.9\n",
            "218 98.0\n",
            "Average return training: 92.6\n",
            "219 23.0\n",
            "Average return training: 92.59\n",
            "220 41.0\n",
            "Average return training: 92.6\n",
            "221 41.0\n",
            "Average return training: 92.71\n",
            "222 64.0\n",
            "Average return training: 93.0\n",
            "Average return over 25 episodes of playing: 48.0\n",
            "223 48.0\n",
            "Average return training: 92.12\n",
            "224 25.0\n",
            "Average return training: 92.22\n",
            "225 34.0\n",
            "Average return training: 92.38\n",
            "226 72.0\n",
            "Average return training: 92.48\n",
            "227 92.0\n",
            "Average return training: 92.95\n",
            "228 60.0\n",
            "Average return training: 92.24\n",
            "229 81.0\n",
            "Average return training: 92.26\n",
            "230 64.0\n",
            "Average return training: 92.29\n",
            "Average return over 25 episodes of playing: 125.0\n",
            "231 115.0\n",
            "Average return training: 93.0\n",
            "232 86.0\n",
            "Average return training: 92.72\n",
            "233 83.0\n",
            "Average return training: 93.26\n",
            "Average return over 25 episodes of playing: 170.44\n",
            "234 373.0\n",
            "Average return training: 96.49\n",
            "235 157.0\n",
            "Average return training: 97.66\n",
            "Average return over 25 episodes of playing: 287.76\n",
            "236 219.0\n",
            "Average return training: 98.74\n",
            "237 147.0\n",
            "Average return training: 99.35\n",
            "238 143.0\n",
            "Average return training: 100.4\n",
            "239 150.0\n",
            "Average return training: 101.39\n",
            "Average return over 25 episodes of playing: 294.04\n",
            "240 330.0\n",
            "Average return training: 103.94\n",
            "241 184.0\n",
            "Average return training: 105.48\n",
            "Average return over 25 episodes of playing: 201.6\n",
            "242 164.0\n",
            "Average return training: 106.68\n",
            "243 177.0\n",
            "Average return training: 108.19\n",
            "Average return over 25 episodes of playing: 255.44\n",
            "244 363.0\n",
            "Average return training: 111.07\n",
            "245 213.0\n",
            "Average return training: 112.33\n",
            "246 125.0\n",
            "Average return training: 112.65\n",
            "Average return over 25 episodes of playing: 271.08\n",
            "247 371.0\n",
            "Average return training: 115.87\n",
            "248 68.0\n",
            "Average return training: 115.06\n",
            "Average return over 25 episodes of playing: 271.4\n",
            "249 379.0\n",
            "Average return training: 117.76\n",
            "250 144.0\n",
            "Average return training: 118.41\n",
            "Average return over 25 episodes of playing: 278.44\n",
            "251 389.0\n",
            "Average return training: 122.14\n",
            "Average return over 25 episodes of playing: 268.96\n",
            "252 217.0\n",
            "Average return training: 123.61\n",
            "253 232.0\n",
            "Average return training: 125.24\n",
            "Average return over 25 episodes of playing: 273.08\n",
            "254 329.0\n",
            "Average return training: 127.76\n",
            "Average return over 25 episodes of playing: 269.92\n",
            "255 500.0\n",
            "Average return training: 131.69\n",
            "256 352.0\n",
            "Average return training: 134.66\n",
            "Average return over 25 episodes of playing: 257.92\n",
            "257 500.0\n",
            "Average return training: 138.44\n",
            "Average return over 25 episodes of playing: 256.88\n",
            "258 298.0\n",
            "Average return training: 140.13\n",
            "259 149.0\n",
            "Average return training: 140.56\n",
            "Average return over 25 episodes of playing: 243.0\n",
            "260 119.0\n",
            "Average return training: 140.13\n",
            "261 292.0\n",
            "Average return training: 142.43\n",
            "Average return over 25 episodes of playing: 242.52\n",
            "262 340.0\n",
            "Average return training: 145.03\n",
            "263 44.0\n",
            "Average return training: 145.02\n",
            "264 214.0\n",
            "Average return training: 146.32\n",
            "Average return over 25 episodes of playing: 305.68\n",
            "265 239.0\n",
            "Average return training: 147.79\n",
            "266 265.0\n",
            "Average return training: 149.61\n",
            "Average return over 25 episodes of playing: 359.44\n",
            "267 483.0\n",
            "Average return training: 154.03\n",
            "Average return over 25 episodes of playing: 421.48\n",
            "268 272.0\n",
            "Average return training: 156.11\n",
            "Average return over 25 episodes of playing: 373.52\n",
            "269 500.0\n",
            "Average return training: 160.26\n",
            "270 191.0\n",
            "Average return training: 161.13\n",
            "Average return over 25 episodes of playing: 331.92\n",
            "271 500.0\n",
            "Average return training: 165.66\n",
            "Average return over 25 episodes of playing: 269.4\n",
            "272 418.0\n",
            "Average return training: 169.34\n",
            "Average return over 25 episodes of playing: 249.16\n",
            "273 203.0\n",
            "Average return training: 170.4\n",
            "274 273.0\n",
            "Average return training: 172.43\n",
            "275 178.0\n",
            "Average return training: 173.52\n",
            "Average return over 25 episodes of playing: 210.4\n",
            "276 153.0\n",
            "Average return training: 174.14\n",
            "277 208.0\n",
            "Average return training: 174.63\n",
            "Average return over 25 episodes of playing: 197.6\n",
            "278 188.0\n",
            "Average return training: 176.06\n",
            "279 209.0\n",
            "Average return training: 177.66\n",
            "280 221.0\n",
            "Average return training: 179.02\n",
            "Average return over 25 episodes of playing: 238.36\n",
            "281 146.0\n",
            "Average return training: 177.92\n",
            "282 281.0\n",
            "Average return training: 179.76\n",
            "Average return over 25 episodes of playing: 277.68\n",
            "283 500.0\n",
            "Average return training: 183.83\n",
            "Average return over 25 episodes of playing: 347.64\n",
            "284 500.0\n",
            "Average return training: 188.25\n",
            "Average return over 25 episodes of playing: 450.72\n",
            "285 409.0\n",
            "Average return training: 191.35\n",
            "Average return over 25 episodes of playing: 457.44\n",
            "286 414.0\n",
            "Average return training: 194.27\n",
            "Average return over 25 episodes of playing: 446.32\n",
            "287 500.0\n",
            "Average return training: 198.32\n",
            "288 249.0\n",
            "Average return training: 199.88\n",
            "Average return over 25 episodes of playing: 378.08\n",
            "289 302.0\n",
            "Average return training: 201.78\n",
            "Average return over 25 episodes of playing: 325.68\n",
            "290 399.0\n",
            "Average return training: 204.57\n",
            "Average return over 25 episodes of playing: 274.32\n",
            "291 398.0\n",
            "Average return training: 207.54\n",
            "292 258.0\n",
            "Average return training: 208.49\n",
            "Average return over 25 episodes of playing: 249.76\n",
            "293 260.0\n",
            "Average return training: 210.48\n",
            "294 227.0\n",
            "Average return training: 211.72\n",
            "Average return over 25 episodes of playing: 273.64\n",
            "295 300.0\n",
            "Average return training: 212.37\n",
            "296 251.0\n",
            "Average return training: 214.19\n",
            "Average return over 25 episodes of playing: 313.8\n",
            "297 278.0\n",
            "Average return training: 215.85\n",
            "298 300.0\n",
            "Average return training: 216.98\n",
            "Average return over 25 episodes of playing: 321.72\n",
            "299 378.0\n",
            "Average return training: 219.4\n",
            "Average return over 25 episodes of playing: 313.16\n",
            "300 392.0\n",
            "Average return training: 222.08\n",
            "301 267.0\n",
            "Average return training: 223.4\n",
            "Average return over 25 episodes of playing: 356.04\n",
            "302 500.0\n",
            "Average return training: 227.25\n",
            "Average return over 25 episodes of playing: 411.12\n",
            "303 361.0\n",
            "Average return training: 229.16\n",
            "Average return over 25 episodes of playing: 423.84\n",
            "304 470.0\n",
            "Average return training: 231.58\n",
            "305 113.0\n",
            "Average return training: 231.42\n",
            "Average return over 25 episodes of playing: 475.76\n",
            "306 500.0\n",
            "Average return training: 235.41\n",
            "Average return over 25 episodes of playing: 482.6\n",
            "307 500.0\n",
            "Average return training: 239.1\n",
            "Average return over 25 episodes of playing: 489.68\n",
            "308 500.0\n",
            "Average return training: 243.15\n",
            "Average return over 25 episodes of playing: 440.76\n",
            "309 263.0\n",
            "Average return training: 244.69\n",
            "Average return over 25 episodes of playing: 463.0\n",
            "310 472.0\n",
            "Average return training: 247.69\n",
            "Average return over 25 episodes of playing: 459.72\n",
            "311 455.0\n",
            "Average return training: 251.14\n",
            "312 364.0\n",
            "Average return training: 253.67\n",
            "Average return over 25 episodes of playing: 414.6\n",
            "313 328.0\n",
            "Average return training: 255.52\n",
            "Average return over 25 episodes of playing: 429.36\n",
            "314 445.0\n",
            "Average return training: 258.58\n",
            "Average return over 25 episodes of playing: 435.52\n",
            "315 321.0\n",
            "Average return training: 260.4\n",
            "Average return over 25 episodes of playing: 464.4\n",
            "316 500.0\n",
            "Average return training: 264.22\n",
            "317 389.0\n",
            "Average return training: 267.0\n",
            "Average return over 25 episodes of playing: 452.68\n",
            "318 500.0\n",
            "Average return training: 271.02\n",
            "Average return over 25 episodes of playing: 481.4\n",
            "319 500.0\n",
            "Average return training: 275.79\n",
            "Average return over 25 episodes of playing: 413.48\n",
            "320 500.0\n",
            "Average return training: 280.38\n",
            "Average return over 25 episodes of playing: 423.24\n",
            "321 245.0\n",
            "Average return training: 282.42\n",
            "322 280.0\n",
            "Average return training: 284.58\n",
            "Average return over 25 episodes of playing: 414.56\n",
            "323 422.0\n",
            "Average return training: 288.32\n",
            "Average return over 25 episodes of playing: 390.48\n",
            "324 129.0\n",
            "Average return training: 289.36\n",
            "325 317.0\n",
            "Average return training: 292.19\n",
            "Average return over 25 episodes of playing: 403.56\n",
            "326 222.0\n",
            "Average return training: 293.69\n",
            "327 164.0\n",
            "Average return training: 294.41\n",
            "Average return over 25 episodes of playing: 422.4\n",
            "328 500.0\n",
            "Average return training: 298.81\n",
            "Average return over 25 episodes of playing: 446.0\n",
            "329 500.0\n",
            "Average return training: 303.0\n",
            "Average return over 25 episodes of playing: 482.8\n",
            "330 500.0\n",
            "Average return training: 307.36\n",
            "Average return over 25 episodes of playing: 479.28\n",
            "331 500.0\n",
            "Average return training: 311.21\n",
            "Average return over 25 episodes of playing: 491.12\n",
            "332 500.0\n",
            "Average return training: 315.35\n",
            "Average return over 25 episodes of playing: 479.64\n",
            "333 500.0\n",
            "Average return training: 319.52\n",
            "Average return over 100 episodes of trained agent: 486.5\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:aqlsdy3d) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 176... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95b7af2cb84d4434baf86a7f680b1ff2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average return over 100 episodes of training</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇█</td></tr><tr><td>Average return over 25 episodes of playing</td><td>▁▁▁▁▂▂▂▂▃▃▄▃▅▄▅▅▅▅▅▇▆▄▄▆█▆▄▅▅▇█▇▇▇█▇▇▇██</td></tr><tr><td>episode</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average return over 100 episodes of training</td><td>319.52</td></tr><tr><td>Average return over 25 episodes of playing</td><td>479.64</td></tr><tr><td>episode</td><td>333</td></tr><tr><td>step</td><td>45000</td></tr></table>\n",
              "</div></div>\n",
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">celestial-eon-303</strong>: <a href=\"https://wandb.ai/raisa/Reinforce-Baseline-CartPole/runs/aqlsdy3d\" target=\"_blank\">https://wandb.ai/raisa/Reinforce-Baseline-CartPole/runs/aqlsdy3d</a><br/>\n",
              "Find logs at: <code>./wandb/run-20220116_191633-aqlsdy3d/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:aqlsdy3d). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/raisa/Reinforce-Baseline-CartPole/runs/35dutxyx\" target=\"_blank\">visionary-aardvark-304</a></strong> to <a href=\"https://wandb.ai/raisa/Reinforce-Baseline-CartPole\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SEED: 34\n",
            "1 21.0\n",
            "2 20.0\n",
            "3 13.0\n",
            "4 16.0\n",
            "5 42.0\n",
            "6 27.0\n",
            "7 18.0\n",
            "8 16.0\n",
            "9 21.0\n",
            "10 38.0\n",
            "11 15.0\n",
            "12 15.0\n",
            "13 33.0\n",
            "14 31.0\n",
            "15 44.0\n",
            "16 29.0\n",
            "17 9.0\n",
            "18 20.0\n",
            "19 30.0\n",
            "Average return over 25 episodes of playing: 24.8\n",
            "20 90.0\n",
            "21 27.0\n",
            "22 54.0\n",
            "23 12.0\n",
            "24 21.0\n",
            "25 14.0\n",
            "26 12.0\n",
            "27 27.0\n",
            "28 19.0\n",
            "29 20.0\n",
            "30 13.0\n",
            "31 41.0\n",
            "32 25.0\n",
            "33 10.0\n",
            "34 10.0\n",
            "35 15.0\n",
            "36 17.0\n",
            "37 25.0\n",
            "38 19.0\n",
            "39 26.0\n",
            "40 19.0\n",
            "41 15.0\n",
            "Average return over 25 episodes of playing: 21.16\n",
            "42 21.0\n",
            "43 24.0\n",
            "44 10.0\n",
            "45 17.0\n",
            "46 22.0\n",
            "47 14.0\n",
            "48 45.0\n",
            "49 10.0\n",
            "50 17.0\n",
            "51 26.0\n",
            "52 12.0\n",
            "53 30.0\n",
            "54 11.0\n",
            "55 12.0\n",
            "56 25.0\n",
            "57 29.0\n",
            "58 13.0\n",
            "59 17.0\n",
            "60 12.0\n",
            "61 18.0\n",
            "62 40.0\n",
            "63 17.0\n",
            "64 12.0\n",
            "65 24.0\n",
            "66 18.0\n",
            "Average return over 25 episodes of playing: 21.68\n",
            "67 35.0\n",
            "68 67.0\n",
            "69 17.0\n",
            "70 30.0\n",
            "71 34.0\n",
            "72 33.0\n",
            "73 68.0\n",
            "74 35.0\n",
            "75 34.0\n",
            "76 18.0\n",
            "77 28.0\n",
            "78 22.0\n",
            "79 19.0\n",
            "80 22.0\n",
            "81 28.0\n",
            "82 16.0\n",
            "Average return over 25 episodes of playing: 26.4\n",
            "83 35.0\n",
            "84 41.0\n",
            "85 22.0\n",
            "86 41.0\n",
            "87 33.0\n",
            "88 21.0\n",
            "89 11.0\n",
            "90 29.0\n",
            "91 23.0\n",
            "92 21.0\n",
            "93 11.0\n",
            "94 25.0\n",
            "95 32.0\n",
            "96 22.0\n",
            "97 43.0\n",
            "98 50.0\n",
            "99 31.0\n",
            "Average return over 25 episodes of playing: 26.2\n",
            "100 18.0\n",
            "101 11.0\n",
            "Average return training: 24.9\n",
            "102 14.0\n",
            "Average return training: 24.84\n",
            "103 32.0\n",
            "Average return training: 25.03\n",
            "104 14.0\n",
            "Average return training: 25.01\n",
            "105 45.0\n",
            "Average return training: 25.04\n",
            "106 26.0\n",
            "Average return training: 25.03\n",
            "107 19.0\n",
            "Average return training: 25.04\n",
            "108 21.0\n",
            "Average return training: 25.09\n",
            "109 44.0\n",
            "Average return training: 25.32\n",
            "110 11.0\n",
            "Average return training: 25.05\n",
            "111 61.0\n",
            "Average return training: 25.51\n",
            "112 31.0\n",
            "Average return training: 25.67\n",
            "113 24.0\n",
            "Average return training: 25.58\n",
            "114 22.0\n",
            "Average return training: 25.49\n",
            "115 12.0\n",
            "Average return training: 25.17\n",
            "116 43.0\n",
            "Average return training: 25.31\n",
            "117 38.0\n",
            "Average return training: 25.6\n",
            "118 27.0\n",
            "Average return training: 25.67\n",
            "Average return over 25 episodes of playing: 35.68\n",
            "119 52.0\n",
            "Average return training: 25.89\n",
            "120 24.0\n",
            "Average return training: 25.23\n",
            "121 42.0\n",
            "Average return training: 25.38\n",
            "122 45.0\n",
            "Average return training: 25.29\n",
            "123 39.0\n",
            "Average return training: 25.56\n",
            "124 38.0\n",
            "Average return training: 25.73\n",
            "125 18.0\n",
            "Average return training: 25.77\n",
            "126 31.0\n",
            "Average return training: 25.96\n",
            "127 36.0\n",
            "Average return training: 26.05\n",
            "128 51.0\n",
            "Average return training: 26.37\n",
            "129 22.0\n",
            "Average return training: 26.39\n",
            "130 18.0\n",
            "Average return training: 26.44\n",
            "131 14.0\n",
            "Average return training: 26.17\n",
            "132 36.0\n",
            "Average return training: 26.28\n",
            "133 21.0\n",
            "Average return training: 26.39\n",
            "Average return over 25 episodes of playing: 34.08\n",
            "134 26.0\n",
            "Average return training: 26.55\n",
            "135 42.0\n",
            "Average return training: 26.82\n",
            "136 38.0\n",
            "Average return training: 27.03\n",
            "137 76.0\n",
            "Average return training: 27.54\n",
            "138 19.0\n",
            "Average return training: 27.54\n",
            "139 39.0\n",
            "Average return training: 27.67\n",
            "140 34.0\n",
            "Average return training: 27.82\n",
            "141 19.0\n",
            "Average return training: 27.86\n",
            "142 20.0\n",
            "Average return training: 27.85\n",
            "143 60.0\n",
            "Average return training: 28.21\n",
            "144 125.0\n",
            "Average return training: 29.36\n",
            "Average return over 25 episodes of playing: 43.48\n",
            "145 83.0\n",
            "Average return training: 30.02\n",
            "146 46.0\n",
            "Average return training: 30.26\n",
            "147 60.0\n",
            "Average return training: 30.72\n",
            "148 23.0\n",
            "Average return training: 30.5\n",
            "149 67.0\n",
            "Average return training: 31.07\n",
            "150 35.0\n",
            "Average return training: 31.25\n",
            "151 19.0\n",
            "Average return training: 31.18\n",
            "152 38.0\n",
            "Average return training: 31.44\n",
            "153 45.0\n",
            "Average return training: 31.59\n",
            "154 44.0\n",
            "Average return training: 31.92\n",
            "155 29.0\n",
            "Average return training: 32.09\n",
            "Average return over 25 episodes of playing: 44.92\n",
            "156 38.0\n",
            "Average return training: 32.22\n",
            "157 66.0\n",
            "Average return training: 32.59\n",
            "158 89.0\n",
            "Average return training: 33.35\n",
            "159 21.0\n",
            "Average return training: 33.39\n",
            "160 19.0\n",
            "Average return training: 33.46\n",
            "161 115.0\n",
            "Average return training: 34.43\n",
            "162 32.0\n",
            "Average return training: 34.35\n",
            "163 42.0\n",
            "Average return training: 34.6\n",
            "164 27.0\n",
            "Average return training: 34.75\n",
            "165 49.0\n",
            "Average return training: 35.0\n",
            "166 25.0\n",
            "Average return training: 35.07\n",
            "Average return over 25 episodes of playing: 58.0\n",
            "167 20.0\n",
            "Average return training: 34.92\n",
            "168 27.0\n",
            "Average return training: 34.52\n",
            "169 51.0\n",
            "Average return training: 34.86\n",
            "170 31.0\n",
            "Average return training: 34.87\n",
            "171 40.0\n",
            "Average return training: 34.93\n",
            "172 48.0\n",
            "Average return training: 35.08\n",
            "173 101.0\n",
            "Average return training: 35.41\n",
            "174 32.0\n",
            "Average return training: 35.38\n",
            "175 75.0\n",
            "Average return training: 35.79\n",
            "176 50.0\n",
            "Average return training: 36.11\n",
            "Average return over 25 episodes of playing: 50.56\n",
            "177 46.0\n",
            "Average return training: 36.29\n",
            "178 78.0\n",
            "Average return training: 36.85\n",
            "179 111.0\n",
            "Average return training: 37.77\n",
            "180 27.0\n",
            "Average return training: 37.82\n",
            "181 22.0\n",
            "Average return training: 37.76\n",
            "182 22.0\n",
            "Average return training: 37.82\n",
            "183 12.0\n",
            "Average return training: 37.59\n",
            "184 13.0\n",
            "Average return training: 37.31\n",
            "185 75.0\n",
            "Average return training: 37.84\n",
            "186 56.0\n",
            "Average return training: 37.99\n",
            "187 64.0\n",
            "Average return training: 38.3\n",
            "Average return over 25 episodes of playing: 65.32\n",
            "188 71.0\n",
            "Average return training: 38.8\n",
            "189 81.0\n",
            "Average return training: 39.5\n",
            "190 96.0\n",
            "Average return training: 40.17\n",
            "191 39.0\n",
            "Average return training: 40.33\n",
            "192 41.0\n",
            "Average return training: 40.53\n",
            "193 90.0\n",
            "Average return training: 41.32\n",
            "194 71.0\n",
            "Average return training: 41.78\n",
            "Average return over 25 episodes of playing: 94.68\n",
            "195 78.0\n",
            "Average return training: 42.24\n",
            "196 137.0\n",
            "Average return training: 43.39\n",
            "197 97.0\n",
            "Average return training: 43.93\n",
            "198 171.0\n",
            "Average return training: 45.14\n",
            "199 29.0\n",
            "Average return training: 45.12\n",
            "Average return over 25 episodes of playing: 132.8\n",
            "200 213.0\n",
            "Average return training: 47.07\n",
            "201 75.0\n",
            "Average return training: 47.71\n",
            "202 108.0\n",
            "Average return training: 48.65\n",
            "Average return over 25 episodes of playing: 205.36\n",
            "203 244.0\n",
            "Average return training: 50.77\n",
            "204 134.0\n",
            "Average return training: 51.97\n",
            "205 118.0\n",
            "Average return training: 52.7\n",
            "Average return over 25 episodes of playing: 165.52\n",
            "206 212.0\n",
            "Average return training: 54.56\n",
            "207 223.0\n",
            "Average return training: 56.6\n",
            "208 153.0\n",
            "Average return training: 57.92\n",
            "Average return over 25 episodes of playing: 167.56\n",
            "209 262.0\n",
            "Average return training: 60.1\n",
            "210 117.0\n",
            "Average return training: 61.16\n",
            "211 66.0\n",
            "Average return training: 61.21\n",
            "Average return over 25 episodes of playing: 145.36\n",
            "212 152.0\n",
            "Average return training: 62.42\n",
            "213 250.0\n",
            "Average return training: 64.68\n",
            "214 164.0\n",
            "Average return training: 66.1\n",
            "Average return over 25 episodes of playing: 165.4\n",
            "215 297.0\n",
            "Average return training: 68.95\n",
            "216 86.0\n",
            "Average return training: 69.38\n",
            "217 79.0\n",
            "Average return training: 69.79\n",
            "Average return over 25 episodes of playing: 252.8\n",
            "218 340.0\n",
            "Average return training: 72.92\n",
            "Average return over 25 episodes of playing: 223.08\n",
            "219 427.0\n",
            "Average return training: 76.67\n",
            "220 273.0\n",
            "Average return training: 79.16\n",
            "Average return over 25 episodes of playing: 319.04\n",
            "221 474.0\n",
            "Average return training: 83.48\n",
            "Average return over 25 episodes of playing: 360.28\n",
            "222 369.0\n",
            "Average return training: 86.72\n",
            "Average return over 25 episodes of playing: 311.84\n",
            "223 295.0\n",
            "Average return training: 89.28\n",
            "224 211.0\n",
            "Average return training: 91.01\n",
            "225 61.0\n",
            "Average return training: 91.44\n",
            "Average return over 25 episodes of playing: 201.2\n",
            "226 211.0\n",
            "Average return training: 93.24\n",
            "227 160.0\n",
            "Average return training: 94.48\n",
            "228 175.0\n",
            "Average return training: 95.72\n",
            "Average return over 25 episodes of playing: 133.04\n",
            "229 126.0\n",
            "Average return training: 96.76\n",
            "230 108.0\n",
            "Average return training: 97.66\n",
            "231 107.0\n",
            "Average return training: 98.59\n",
            "232 131.0\n",
            "Average return training: 99.54\n",
            "Average return over 25 episodes of playing: 124.64\n",
            "233 148.0\n",
            "Average return training: 100.81\n",
            "234 57.0\n",
            "Average return training: 101.12\n",
            "235 158.0\n",
            "Average return training: 102.28\n",
            "236 139.0\n",
            "Average return training: 103.29\n",
            "Average return over 25 episodes of playing: 190.2\n",
            "237 216.0\n",
            "Average return training: 104.69\n",
            "238 209.0\n",
            "Average return training: 106.59\n",
            "Average return over 25 episodes of playing: 291.28\n",
            "239 333.0\n",
            "Average return training: 109.53\n",
            "Average return over 25 episodes of playing: 368.4\n",
            "240 337.0\n",
            "Average return training: 112.56\n",
            "241 266.0\n",
            "Average return training: 115.03\n",
            "Average return over 25 episodes of playing: 386.88\n",
            "242 500.0\n",
            "Average return training: 119.83\n",
            "Average return over 25 episodes of playing: 418.8\n",
            "243 500.0\n",
            "Average return training: 124.23\n",
            "Average return over 25 episodes of playing: 401.04\n",
            "244 500.0\n",
            "Average return training: 127.98\n",
            "Average return over 25 episodes of playing: 364.84\n",
            "245 500.0\n",
            "Average return training: 132.15\n",
            "Average return over 25 episodes of playing: 461.16\n",
            "246 474.0\n",
            "Average return training: 136.43\n",
            "Average return over 25 episodes of playing: 342.08\n",
            "247 500.0\n",
            "Average return training: 140.83\n",
            "248 191.0\n",
            "Average return training: 142.51\n",
            "Average return over 25 episodes of playing: 358.0\n",
            "249 500.0\n",
            "Average return training: 146.84\n",
            "Average return over 25 episodes of playing: 370.72\n",
            "250 500.0\n",
            "Average return training: 151.49\n",
            "Average return over 25 episodes of playing: 342.64\n",
            "251 334.0\n",
            "Average return training: 154.64\n",
            "Average return over 25 episodes of playing: 341.52\n",
            "252 437.0\n",
            "Average return training: 158.63\n",
            "Average return over 25 episodes of playing: 306.28\n",
            "253 365.0\n",
            "Average return training: 161.83\n",
            "254 382.0\n",
            "Average return training: 165.21\n",
            "Average return over 25 episodes of playing: 284.8\n",
            "255 454.0\n",
            "Average return training: 169.46\n",
            "Average return over 25 episodes of playing: 287.28\n",
            "256 398.0\n",
            "Average return training: 173.06\n",
            "Average return over 25 episodes of playing: 276.04\n",
            "257 441.0\n",
            "Average return training: 176.81\n",
            "Average return over 25 episodes of playing: 267.84\n",
            "258 500.0\n",
            "Average return training: 180.92\n",
            "259 173.0\n",
            "Average return training: 182.44\n",
            "Average return over 25 episodes of playing: 319.96\n",
            "260 259.0\n",
            "Average return training: 184.84\n",
            "261 208.0\n",
            "Average return training: 185.77\n",
            "Average return over 25 episodes of playing: 241.68\n",
            "262 500.0\n",
            "Average return training: 190.45\n",
            "Average return over 25 episodes of playing: 320.4\n",
            "263 204.0\n",
            "Average return training: 192.07\n",
            "264 322.0\n",
            "Average return training: 195.02\n",
            "Average return over 25 episodes of playing: 341.08\n",
            "265 310.0\n",
            "Average return training: 197.63\n",
            "Average return over 25 episodes of playing: 340.04\n",
            "266 458.0\n",
            "Average return training: 201.96\n",
            "Average return over 25 episodes of playing: 340.16\n",
            "267 400.0\n",
            "Average return training: 205.76\n",
            "Average return over 25 episodes of playing: 415.6\n",
            "268 500.0\n",
            "Average return training: 210.49\n",
            "269 182.0\n",
            "Average return training: 211.8\n",
            "Average return over 25 episodes of playing: 408.48\n",
            "270 500.0\n",
            "Average return training: 216.49\n",
            "Average return over 25 episodes of playing: 414.52\n",
            "271 500.0\n",
            "Average return training: 221.09\n",
            "Average return over 25 episodes of playing: 339.0\n",
            "272 369.0\n",
            "Average return training: 224.3\n",
            "273 207.0\n",
            "Average return training: 225.36\n",
            "Average return over 25 episodes of playing: 216.84\n",
            "274 195.0\n",
            "Average return training: 226.99\n",
            "275 211.0\n",
            "Average return training: 228.35\n",
            "276 212.0\n",
            "Average return training: 229.97\n",
            "Average return over 25 episodes of playing: 184.84\n",
            "277 197.0\n",
            "Average return training: 231.48\n",
            "278 165.0\n",
            "Average return training: 232.35\n",
            "Average return over 25 episodes of playing: 180.6\n",
            "279 205.0\n",
            "Average return training: 233.29\n",
            "280 165.0\n",
            "Average return training: 234.67\n",
            "281 180.0\n",
            "Average return training: 236.25\n",
            "Average return over 25 episodes of playing: 215.36\n",
            "282 193.0\n",
            "Average return training: 237.96\n",
            "283 212.0\n",
            "Average return training: 239.96\n",
            "Average return over 25 episodes of playing: 221.72\n",
            "284 225.0\n",
            "Average return training: 242.08\n",
            "285 283.0\n",
            "Average return training: 244.16\n",
            "Average return over 25 episodes of playing: 265.52\n",
            "286 285.0\n",
            "Average return training: 246.45\n",
            "287 260.0\n",
            "Average return training: 248.41\n",
            "Average return over 25 episodes of playing: 302.92\n",
            "288 363.0\n",
            "Average return training: 251.33\n",
            "Average return over 25 episodes of playing: 309.44\n",
            "289 333.0\n",
            "Average return training: 253.85\n",
            "290 287.0\n",
            "Average return training: 255.76\n",
            "Average return over 25 episodes of playing: 346.84\n",
            "291 461.0\n",
            "Average return training: 259.98\n",
            "Average return over 25 episodes of playing: 407.48\n",
            "292 404.0\n",
            "Average return training: 263.61\n",
            "Average return over 25 episodes of playing: 471.64\n",
            "293 394.0\n",
            "Average return training: 266.65\n",
            "Average return over 25 episodes of playing: 479.24\n",
            "294 500.0\n",
            "Average return training: 270.94\n",
            "Average return over 25 episodes of playing: 480.0\n",
            "295 500.0\n",
            "Average return training: 275.16\n",
            "Average return over 25 episodes of playing: 492.88\n",
            "296 500.0\n",
            "Average return training: 278.79\n",
            "Average return over 25 episodes of playing: 469.4\n",
            "297 500.0\n",
            "Average return training: 282.82\n",
            "Average return over 100 episodes of trained agent: 476.71\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:35dutxyx) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 210... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4059350189204ee793a98052fcdae5ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average return over 100 episodes of training</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▅▅▆▆▇▇▇▇█</td></tr><tr><td>Average return over 25 episodes of playing</td><td>▁▁▁▁▁▁▁▂▄▃▃▅▆▅▄▃▅▇▇▆▆▆▆▅▅▅▄▆▆▇▇▆▃▄▅▅▆███</td></tr><tr><td>episode</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average return over 100 episodes of training</td><td>282.82</td></tr><tr><td>Average return over 25 episodes of playing</td><td>469.4</td></tr><tr><td>episode</td><td>297</td></tr><tr><td>step</td><td>35000</td></tr></table>\n",
              "</div></div>\n",
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">visionary-aardvark-304</strong>: <a href=\"https://wandb.ai/raisa/Reinforce-Baseline-CartPole/runs/35dutxyx\" target=\"_blank\">https://wandb.ai/raisa/Reinforce-Baseline-CartPole/runs/35dutxyx</a><br/>\n",
              "Find logs at: <code>./wandb/run-20220116_192154-35dutxyx/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:35dutxyx). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/raisa/Reinforce-Baseline-CartPole/runs/jwq61hp3\" target=\"_blank\">iconic-microwave-305</a></strong> to <a href=\"https://wandb.ai/raisa/Reinforce-Baseline-CartPole\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SEED: 56\n",
            "1 15.0\n",
            "2 21.0\n",
            "3 38.0\n",
            "4 14.0\n",
            "5 14.0\n",
            "6 66.0\n",
            "7 10.0\n",
            "8 9.0\n",
            "9 20.0\n",
            "10 10.0\n",
            "11 11.0\n",
            "12 13.0\n",
            "13 16.0\n",
            "14 23.0\n",
            "15 17.0\n",
            "16 30.0\n",
            "17 13.0\n",
            "18 45.0\n",
            "19 14.0\n",
            "20 29.0\n",
            "21 25.0\n",
            "22 11.0\n",
            "23 15.0\n",
            "Average return over 25 episodes of playing: 22.12\n",
            "24 29.0\n",
            "25 25.0\n",
            "26 24.0\n",
            "27 21.0\n",
            "28 17.0\n",
            "29 26.0\n",
            "30 11.0\n",
            "31 33.0\n",
            "32 16.0\n",
            "33 68.0\n",
            "34 33.0\n",
            "35 33.0\n",
            "36 40.0\n",
            "37 21.0\n",
            "38 21.0\n",
            "39 17.0\n",
            "40 15.0\n",
            "41 9.0\n",
            "42 15.0\n",
            "43 12.0\n",
            "44 10.0\n",
            "Average return over 25 episodes of playing: 23.24\n",
            "45 36.0\n",
            "46 22.0\n",
            "47 15.0\n",
            "48 16.0\n",
            "49 25.0\n",
            "50 24.0\n",
            "51 12.0\n",
            "52 13.0\n",
            "53 15.0\n",
            "54 19.0\n",
            "55 25.0\n",
            "56 11.0\n",
            "57 18.0\n",
            "58 16.0\n",
            "59 28.0\n",
            "60 26.0\n",
            "61 21.0\n",
            "62 13.0\n",
            "63 12.0\n",
            "64 64.0\n",
            "65 21.0\n",
            "66 20.0\n",
            "67 14.0\n",
            "Average return over 25 episodes of playing: 21.64\n",
            "68 45.0\n",
            "69 11.0\n",
            "70 31.0\n",
            "71 21.0\n",
            "72 17.0\n",
            "73 11.0\n",
            "74 23.0\n",
            "75 19.0\n",
            "76 37.0\n",
            "77 17.0\n",
            "78 26.0\n",
            "79 39.0\n",
            "80 55.0\n",
            "81 16.0\n",
            "82 18.0\n",
            "83 21.0\n",
            "84 34.0\n",
            "85 12.0\n",
            "86 16.0\n",
            "87 24.0\n",
            "88 18.0\n",
            "89 22.0\n",
            "Average return over 25 episodes of playing: 24.6\n",
            "90 19.0\n",
            "91 32.0\n",
            "92 22.0\n",
            "93 13.0\n",
            "94 28.0\n",
            "95 25.0\n",
            "96 19.0\n",
            "97 17.0\n",
            "98 23.0\n",
            "99 32.0\n",
            "100 12.0\n",
            "101 20.0\n",
            "Average return training: 22.41\n",
            "102 29.0\n",
            "Average return training: 22.49\n",
            "103 19.0\n",
            "Average return training: 22.3\n",
            "104 40.0\n",
            "Average return training: 22.56\n",
            "105 19.0\n",
            "Average return training: 22.61\n",
            "106 13.0\n",
            "Average return training: 22.08\n",
            "107 12.0\n",
            "Average return training: 22.1\n",
            "108 53.0\n",
            "Average return training: 22.54\n",
            "109 34.0\n",
            "Average return training: 22.68\n",
            "110 14.0\n",
            "Average return training: 22.72\n",
            "Average return over 25 episodes of playing: 21.12\n",
            "111 18.0\n",
            "Average return training: 22.79\n",
            "112 18.0\n",
            "Average return training: 22.84\n",
            "113 14.0\n",
            "Average return training: 22.82\n",
            "114 28.0\n",
            "Average return training: 22.87\n",
            "115 29.0\n",
            "Average return training: 22.99\n",
            "116 10.0\n",
            "Average return training: 22.79\n",
            "117 19.0\n",
            "Average return training: 22.85\n",
            "118 53.0\n",
            "Average return training: 22.93\n",
            "119 14.0\n",
            "Average return training: 22.93\n",
            "120 11.0\n",
            "Average return training: 22.75\n",
            "121 15.0\n",
            "Average return training: 22.65\n",
            "122 20.0\n",
            "Average return training: 22.74\n",
            "123 51.0\n",
            "Average return training: 23.1\n",
            "124 17.0\n",
            "Average return training: 22.98\n",
            "125 23.0\n",
            "Average return training: 22.96\n",
            "126 12.0\n",
            "Average return training: 22.84\n",
            "127 12.0\n",
            "Average return training: 22.75\n",
            "128 15.0\n",
            "Average return training: 22.73\n",
            "129 39.0\n",
            "Average return training: 22.86\n",
            "130 28.0\n",
            "Average return training: 23.03\n",
            "131 19.0\n",
            "Average return training: 22.89\n",
            "132 16.0\n",
            "Average return training: 22.89\n",
            "133 24.0\n",
            "Average return training: 22.45\n",
            "Average return over 25 episodes of playing: 24.44\n",
            "134 11.0\n",
            "Average return training: 22.23\n",
            "135 24.0\n",
            "Average return training: 22.14\n",
            "136 36.0\n",
            "Average return training: 22.1\n",
            "137 32.0\n",
            "Average return training: 22.21\n",
            "138 28.0\n",
            "Average return training: 22.28\n",
            "139 33.0\n",
            "Average return training: 22.44\n",
            "140 21.0\n",
            "Average return training: 22.5\n",
            "141 25.0\n",
            "Average return training: 22.66\n",
            "142 29.0\n",
            "Average return training: 22.8\n",
            "143 21.0\n",
            "Average return training: 22.89\n",
            "144 12.0\n",
            "Average return training: 22.91\n",
            "145 35.0\n",
            "Average return training: 22.9\n",
            "146 58.0\n",
            "Average return training: 23.26\n",
            "147 19.0\n",
            "Average return training: 23.3\n",
            "148 28.0\n",
            "Average return training: 23.42\n",
            "149 43.0\n",
            "Average return training: 23.6\n",
            "150 12.0\n",
            "Average return training: 23.48\n",
            "151 34.0\n",
            "Average return training: 23.7\n",
            "Average return over 25 episodes of playing: 25.52\n",
            "152 22.0\n",
            "Average return training: 23.79\n",
            "153 25.0\n",
            "Average return training: 23.89\n",
            "154 65.0\n",
            "Average return training: 24.35\n",
            "155 41.0\n",
            "Average return training: 24.51\n",
            "156 17.0\n",
            "Average return training: 24.57\n",
            "157 31.0\n",
            "Average return training: 24.7\n",
            "158 16.0\n",
            "Average return training: 24.7\n",
            "159 65.0\n",
            "Average return training: 25.07\n",
            "160 56.0\n",
            "Average return training: 25.37\n",
            "161 23.0\n",
            "Average return training: 25.39\n",
            "162 24.0\n",
            "Average return training: 25.5\n",
            "163 27.0\n",
            "Average return training: 25.65\n",
            "164 29.0\n",
            "Average return training: 25.3\n",
            "165 39.0\n",
            "Average return training: 25.48\n",
            "Average return over 25 episodes of playing: 40.52\n",
            "166 25.0\n",
            "Average return training: 25.53\n",
            "167 45.0\n",
            "Average return training: 25.84\n",
            "168 44.0\n",
            "Average return training: 25.83\n",
            "169 15.0\n",
            "Average return training: 25.87\n",
            "170 21.0\n",
            "Average return training: 25.77\n",
            "171 31.0\n",
            "Average return training: 25.87\n",
            "172 40.0\n",
            "Average return training: 26.1\n",
            "173 87.0\n",
            "Average return training: 26.86\n",
            "174 89.0\n",
            "Average return training: 27.52\n",
            "175 55.0\n",
            "Average return training: 27.88\n",
            "176 38.0\n",
            "Average return training: 27.89\n",
            "177 16.0\n",
            "Average return training: 27.88\n",
            "Average return over 25 episodes of playing: 64.2\n",
            "178 39.0\n",
            "Average return training: 28.01\n",
            "179 58.0\n",
            "Average return training: 28.2\n",
            "180 22.0\n",
            "Average return training: 27.87\n",
            "181 34.0\n",
            "Average return training: 28.05\n",
            "182 57.0\n",
            "Average return training: 28.44\n",
            "183 51.0\n",
            "Average return training: 28.74\n",
            "184 51.0\n",
            "Average return training: 28.91\n",
            "185 58.0\n",
            "Average return training: 29.37\n",
            "186 73.0\n",
            "Average return training: 29.94\n",
            "187 26.0\n",
            "Average return training: 29.96\n",
            "188 24.0\n",
            "Average return training: 30.02\n",
            "Average return over 25 episodes of playing: 60.36\n",
            "189 68.0\n",
            "Average return training: 30.48\n",
            "190 298.0\n",
            "Average return training: 33.27\n",
            "191 63.0\n",
            "Average return training: 33.58\n",
            "192 59.0\n",
            "Average return training: 33.95\n",
            "Average return over 25 episodes of playing: 80.56\n",
            "193 120.0\n",
            "Average return training: 35.02\n",
            "194 120.0\n",
            "Average return training: 35.94\n",
            "195 90.0\n",
            "Average return training: 36.59\n",
            "196 157.0\n",
            "Average return training: 37.97\n",
            "Average return over 25 episodes of playing: 111.0\n",
            "197 152.0\n",
            "Average return training: 39.32\n",
            "198 166.0\n",
            "Average return training: 40.75\n",
            "199 68.0\n",
            "Average return training: 41.11\n",
            "200 34.0\n",
            "Average return training: 41.33\n",
            "201 87.0\n",
            "Average return training: 42.0\n",
            "Average return over 25 episodes of playing: 81.64\n",
            "202 101.0\n",
            "Average return training: 42.72\n",
            "203 113.0\n",
            "Average return training: 43.66\n",
            "204 29.0\n",
            "Average return training: 43.55\n",
            "205 95.0\n",
            "Average return training: 44.31\n",
            "206 66.0\n",
            "Average return training: 44.84\n",
            "Average return over 25 episodes of playing: 142.52\n",
            "207 156.0\n",
            "Average return training: 46.28\n",
            "208 230.0\n",
            "Average return training: 48.05\n",
            "Average return over 25 episodes of playing: 217.64\n",
            "209 288.0\n",
            "Average return training: 50.59\n",
            "210 354.0\n",
            "Average return training: 53.99\n",
            "Average return over 25 episodes of playing: 296.8\n",
            "211 248.0\n",
            "Average return training: 56.29\n",
            "212 285.0\n",
            "Average return training: 58.96\n",
            "Average return over 25 episodes of playing: 342.28\n",
            "213 274.0\n",
            "Average return training: 61.56\n",
            "214 290.0\n",
            "Average return training: 64.18\n",
            "Average return over 25 episodes of playing: 402.76\n",
            "215 297.0\n",
            "Average return training: 66.86\n",
            "Average return over 25 episodes of playing: 345.64\n",
            "216 500.0\n",
            "Average return training: 71.76\n",
            "Average return over 25 episodes of playing: 421.48\n",
            "217 500.0\n",
            "Average return training: 76.57\n",
            "Average return over 25 episodes of playing: 378.72\n",
            "218 473.0\n",
            "Average return training: 80.77\n",
            "Average return over 25 episodes of playing: 369.12\n",
            "219 417.0\n",
            "Average return training: 84.8\n",
            "220 244.0\n",
            "Average return training: 87.13\n",
            "221 73.0\n",
            "Average return training: 87.71\n",
            "Average return over 25 episodes of playing: 193.88\n",
            "222 210.0\n",
            "Average return training: 89.61\n",
            "223 118.0\n",
            "Average return training: 90.28\n",
            "224 38.0\n",
            "Average return training: 90.49\n",
            "Average return over 25 episodes of playing: 158.24\n",
            "225 189.0\n",
            "Average return training: 92.15\n",
            "226 200.0\n",
            "Average return training: 94.03\n",
            "227 191.0\n",
            "Average return training: 95.82\n",
            "Average return over 25 episodes of playing: 193.32\n",
            "228 184.0\n",
            "Average return training: 97.51\n",
            "229 243.0\n",
            "Average return training: 99.55\n",
            "Average return over 25 episodes of playing: 231.72\n",
            "230 242.0\n",
            "Average return training: 101.69\n",
            "231 337.0\n",
            "Average return training: 104.87\n",
            "Average return over 25 episodes of playing: 360.88\n",
            "232 426.0\n",
            "Average return training: 108.97\n",
            "233 99.0\n",
            "Average return training: 109.72\n",
            "Average return over 25 episodes of playing: 334.8\n",
            "234 500.0\n",
            "Average return training: 114.61\n",
            "Average return over 25 episodes of playing: 402.16\n",
            "235 465.0\n",
            "Average return training: 119.02\n",
            "Average return over 25 episodes of playing: 417.04\n",
            "236 500.0\n",
            "Average return training: 123.66\n",
            "Average return over 25 episodes of playing: 346.96\n",
            "237 500.0\n",
            "Average return training: 128.34\n",
            "Average return over 25 episodes of playing: 356.08\n",
            "238 126.0\n",
            "Average return training: 129.32\n",
            "239 260.0\n",
            "Average return training: 131.59\n",
            "Average return over 25 episodes of playing: 190.84\n",
            "240 248.0\n",
            "Average return training: 133.86\n",
            "241 210.0\n",
            "Average return training: 135.71\n",
            "242 189.0\n",
            "Average return training: 137.31\n",
            "Average return over 25 episodes of playing: 168.92\n",
            "243 198.0\n",
            "Average return training: 139.08\n",
            "244 164.0\n",
            "Average return training: 140.6\n",
            "245 100.0\n",
            "Average return training: 141.25\n",
            "Average return over 25 episodes of playing: 110.68\n",
            "246 234.0\n",
            "Average return training: 143.01\n",
            "247 39.0\n",
            "Average return training: 143.21\n",
            "248 101.0\n",
            "Average return training: 143.94\n",
            "249 81.0\n",
            "Average return training: 144.32\n",
            "Average return over 25 episodes of playing: 130.12\n",
            "250 305.0\n",
            "Average return training: 147.25\n",
            "251 81.0\n",
            "Average return training: 147.72\n",
            "252 82.0\n",
            "Average return training: 148.32\n",
            "253 84.0\n",
            "Average return training: 148.91\n",
            "Average return over 25 episodes of playing: 155.16\n",
            "254 138.0\n",
            "Average return training: 149.64\n",
            "255 92.0\n",
            "Average return training: 150.15\n",
            "256 89.0\n",
            "Average return training: 150.87\n",
            "257 89.0\n",
            "Average return training: 151.45\n",
            "258 93.0\n",
            "Average return training: 152.22\n",
            "Average return over 25 episodes of playing: 187.76\n",
            "259 227.0\n",
            "Average return training: 153.84\n",
            "260 27.0\n",
            "Average return training: 153.55\n",
            "261 230.0\n",
            "Average return training: 155.62\n",
            "Average return over 25 episodes of playing: 211.24\n",
            "262 248.0\n",
            "Average return training: 157.86\n",
            "263 205.0\n",
            "Average return training: 159.64\n",
            "Average return over 25 episodes of playing: 226.6\n",
            "264 229.0\n",
            "Average return training: 161.64\n",
            "265 214.0\n",
            "Average return training: 163.39\n",
            "Average return over 25 episodes of playing: 248.16\n",
            "266 252.0\n",
            "Average return training: 165.66\n",
            "267 259.0\n",
            "Average return training: 167.8\n",
            "Average return over 25 episodes of playing: 246.6\n",
            "268 329.0\n",
            "Average return training: 170.65\n",
            "269 322.0\n",
            "Average return training: 173.72\n",
            "Average return over 25 episodes of playing: 379.0\n",
            "270 393.0\n",
            "Average return training: 177.44\n",
            "Average return over 25 episodes of playing: 449.76\n",
            "271 486.0\n",
            "Average return training: 181.99\n",
            "Average return over 25 episodes of playing: 491.68\n",
            "272 500.0\n",
            "Average return training: 186.59\n",
            "Average return over 25 episodes of playing: 498.04\n",
            "273 500.0\n",
            "Average return training: 190.72\n",
            "Average return over 25 episodes of playing: 491.92\n",
            "274 500.0\n",
            "Average return training: 194.83\n",
            "Average return over 25 episodes of playing: 492.84\n",
            "275 500.0\n",
            "Average return training: 199.28\n",
            "Average return over 100 episodes of trained agent: 500.0\n"
          ]
        }
      ],
      "source": [
        "##### Reinforce Algorithm with Baseline ###########\n",
        "\n",
        "# Seeds for repeatable training results\n",
        "SEEDS = (12, 34, 56)\n",
        "\n",
        "# Creating two environments: One for training and for playing\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "env2 = gym.make(\"CartPole-v1\")\n",
        "\n",
        "# Looping over different seeds for training different agents\n",
        "for seed in SEEDS:\n",
        "  make_deterministic(seed)\n",
        "  wandb.init(project=\"Reinforce-Baseline-CartPole\", entity=\"raisa\")\n",
        "  print(\"SEED:\", seed)\n",
        "  config = wandb.config\n",
        "\n",
        "  # Defining hyperparameters\n",
        "  gamma = 0.99 # gamma\n",
        "  learning_rate_1 = 0.001 # learning rate for policy network\n",
        "  learning_rate_2 = 0.0005 # learning rate for state-value network\n",
        "  num_episodes = 10000 # maximum number of episodes\n",
        "  hidden_dims_1 = [128, 64, 32] # size of hidden layers in the policy network\n",
        "  hidden_dims_2 = [128, 64, 32] # size of hidden layers in the state-value network\n",
        "\n",
        "  # Logging hyperparameters\n",
        "  config.learning_rate_policy = learning_rate_1\n",
        "  config.learning_rate_value = learning_rate_2\n",
        "  config.gamma = gamma\n",
        "  config.num_episodes = num_episodes\n",
        "  config.hidden_dim_policy = hidden_dims_1\n",
        "  config.hidden_dim_value = hidden_dims_2\n",
        "  config.seed = seed\n",
        "\n",
        "  # Setting the seed for the environments\n",
        "  env.seed(seed)\n",
        "  env.action_space.seed(seed)\n",
        "  env2.seed(seed)\n",
        "  env2.action_space.seed(seed)\n",
        "\n",
        "  # Initializing list for average returns during training\n",
        "  returns_train = []\n",
        "  # Initializing list for average returns during playing\n",
        "  returns_play = []\n",
        "\n",
        "  # Creating neural networks and setting optimizers\n",
        "  policy_model = (Neural_Network(in_dim = int(np.prod(env.observation_space.shape)), out_dim = env.action_space.n, hidden_dim=hidden_dims_1))\n",
        "  state_value_model = (Neural_Network(in_dim = int(np.prod(env.observation_space.shape)), out_dim = 1, hidden_dim=hidden_dims_1))\n",
        "  optimizer = torch.optim.Adam(policy_model.parameters(), lr = learning_rate_1)\n",
        "  optimizer_2 = torch.optim.Adam(state_value_model.parameters(), lr=learning_rate_2)\n",
        "\n",
        "  steps = 0\n",
        "  reward_list = []\n",
        "  disc_rewards = []\n",
        "  discounts = []\n",
        "  returns = []\n",
        "  state_values = []\n",
        "\n",
        "  # Training the agent for number of episodes\n",
        "  for episode in range(0, num_episodes):\n",
        "    step = 0\n",
        "    state = env.reset()\n",
        "    reward_sum = 0\n",
        "    returns.clear()\n",
        "    state_values.clear()\n",
        "    logs = []\n",
        "    while True:\n",
        "      step += 1\n",
        "      steps += 1\n",
        "\n",
        "      # Choosing action and obtaining log value action probability\n",
        "      state_tensor = torch.tensor(state, dtype=torch.float32)\n",
        "      values = policy_model(state_tensor)\n",
        "      distribution = dist.Categorical(logits = values)\n",
        "      action = distribution.sample()\n",
        "      log_value = distribution.log_prob(action)\n",
        "      state_next, reward, done, _ = env.step(action.item())\n",
        "      reward_list.append(reward)\n",
        "      logs.append(log_value)\n",
        "      values_state_value = state_value_model(state_tensor)\n",
        "      state_values.append(values_state_value)\n",
        "      reward_sum += reward\n",
        "      state = state_next\n",
        "\n",
        "      # Playing every 500 steps to obtain the performance of the agent\n",
        "      if steps % 500 == 0:\n",
        "        avg_return_play = play(episodes = 25, step = steps, end = False, envs = env2)\n",
        "        returns_play.append(avg_return_play)\n",
        "      \n",
        "      # Following these steps, if episode has to come to an end \n",
        "      if done:\n",
        "        loss = 0\n",
        "        loss_2 = 0\n",
        "\n",
        "        # Calculating discounts\n",
        "        for i in range(0,step):\n",
        "          discounts.append(gamma**i)\n",
        "\n",
        "        # Calculating discounted returns\n",
        "        for i in range(0, step):\n",
        "          disc_rewards = [x*y for x,y in zip(reward_list,discounts)]\n",
        "          returns.append(torch.tensor(sum(disc_rewards)))\n",
        "          reward_list.pop(0)\n",
        "\n",
        "        returns_tensor = torch.stack(returns)\n",
        "        logs_tensor = torch.stack(logs)\n",
        "        state_value_tensor = torch.stack(state_values)\n",
        "\n",
        "        error = returns_tensor - state_value_tensor\n",
        "        \n",
        "        # Calculating loss for policy network\n",
        "        log_baseline = error.detach() * logs_tensor\n",
        "        loss = (-log_baseline).mean()\n",
        "      \n",
        "        # Optimizing policy network\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculating loss for state-value network\n",
        "        losses = error.pow(2).mean()\n",
        "\n",
        "        # Optimizing state-value network\n",
        "        optimizer_2.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer_2.step()\n",
        "\n",
        "        print(episode + 1, reward_sum)\n",
        "        returns_train.append(reward_sum)\n",
        "        break\n",
        "\n",
        "    # If episode > 100, then print the average reward for the last hundred episodes \n",
        "    if episode + 1  > 100:\n",
        "      x = sum(returns_train[-100:])/100\n",
        "      print(\"Average return training:\", x)\n",
        "      #Log the training average return\n",
        "      wandb.log({\"Average return over 100 episodes of training\": x, \"episode\": episode + 1})\n",
        "\n",
        "    # If training steps >= 2500 and the agent has obtained an average reward of 475 during last 5 times of playing, end training\n",
        "    if steps >= 2500:\n",
        "      if sum(returns_play[-5:]) / 5 >= 475:\n",
        "        break\n",
        "\n",
        "  # Playing after training to obtain end results\n",
        "  play(episodes = 100, step = steps, end = True, envs = env2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Reinforce_Baseline_CartPole.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "20440a3cb2af4e5aa4c2a81958ad006b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "397ba1f5c42c465dad612f3796b8db92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4059350189204ee793a98052fcdae5ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa524deafd0d495eabd5f3913538acb2",
              "IPY_MODEL_b59e4a729a064169afeb395b91600c5f"
            ],
            "layout": "IPY_MODEL_923267aef11b492d986bb28eeffd77a7"
          }
        },
        "4136a7a66bbc461483498cd98e327cdd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "456f8ab95d854d1f873a0d54014e0482": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a275eb8ded84ec0a968bcbea85c6297": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3e1ceffc5094cc9a2be49d2fda3615a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0b862fdb80c4b868225296c904f6b9f",
            "value": 1
          }
        },
        "60a57683952f417cb676cc079ff4373c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "923267aef11b492d986bb28eeffd77a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95b7af2cb84d4434baf86a7f680b1ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2b88aad5a1240c2aead34f00bff4b3a",
              "IPY_MODEL_5a275eb8ded84ec0a968bcbea85c6297"
            ],
            "layout": "IPY_MODEL_456f8ab95d854d1f873a0d54014e0482"
          }
        },
        "a3e1ceffc5094cc9a2be49d2fda3615a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa524deafd0d495eabd5f3913538acb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca39849f156f4f0ba346c9238baecc94",
            "placeholder": "​",
            "style": "IPY_MODEL_60a57683952f417cb676cc079ff4373c",
            "value": " 0.02MB of 0.02MB uploaded (0.00MB deduped)\r"
          }
        },
        "b59e4a729a064169afeb395b91600c5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20440a3cb2af4e5aa4c2a81958ad006b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f760b44c276a42b5aacebfc41cc7e2ab",
            "value": 1
          }
        },
        "c0b862fdb80c4b868225296c904f6b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca39849f156f4f0ba346c9238baecc94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2b88aad5a1240c2aead34f00bff4b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4136a7a66bbc461483498cd98e327cdd",
            "placeholder": "​",
            "style": "IPY_MODEL_397ba1f5c42c465dad612f3796b8db92",
            "value": " 0.02MB of 0.02MB uploaded (0.00MB deduped)\r"
          }
        },
        "f760b44c276a42b5aacebfc41cc7e2ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
